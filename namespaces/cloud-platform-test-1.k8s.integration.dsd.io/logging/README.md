# Logging with Fluentd to ElasticSearch on Kubernetes 

## Introduction
The files within this directory, when deployed together will install Fluentd and will collect all of the logs being generated by every container in the cluster.

Fluentd, in real-time, will transport the collected logs to your specified ElasticSearch endpoint.

These files are a customised version of the official Kubernetes `fluentd-es` templates. [Repo link.](https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch)

This README uses the `test-1` cluster in it's examples, but this information should be applicable to any cluster you are seeking to deploy this on.

## Pre-Reqs
This guide assumes you have already configured or have access to an AWS Hosted ElasticSearch.

## File-Breakdown

### Logging Namespace

The `00.namespace.yaml` file simply creates a 'logging' namespace in the cluster. 

This is where fluent-es will be deployed and therefore has to be the first of the 3 files to be deployed.

It is strongly advised that these 3 files are deployed by deploying all the contents of this directory together. 

Example: `$ kubectl create -f logging/`

### Application & RBAC

The `kube-fluentd-es.yaml` file is the core file that specifies the container and deploys the application. The `fluentd-es` containers are deployed through a `DaemonSet`. This means whenever a new container is created anywhere in the cluster, a `fluentd-es` pod will also be deployed and logging of the container will start automatically. 

In addition to the application's `DaemonSet`, there are an additional 3 parts to the file that handle the RBAC permissions. The parts that handle the RBAC are a `ServiceAccount`, a `ClusterRole`, and a `ClusterRoleBinding`. 

### Application ConfigMap

The `kube-fluentd-es-config.yaml` file is the config file that `fluentd-es` depends on for all of it's default configurations. Don't be overwhelmed by the size of this file as over 99% of it's contents are default and shouldn't be touched. The only part of this file that you should concern yourself with is the very last block of code at the bottom, within the `<match>` tag.

### ElasticSearch Curator

The `elasticsearch-curator.yaml` file is made up of two resources, a ConfigMap and a CronJob. The ConfigMap contains a Python script that generates AWS credentials in the `aws-platforms-integration` account and deletes logs older than 1 month in the `cloud-platform-test` elasticsearch cluster. 

The CronJob is responsible for scheduling the Python script to run every day at 1am. 

## Configuration 

This section of the document will inform you of the areas of the files that require modification for this Fluentd to ElasticSearch logging system to work on your desired cluster. 

As stated before, the files in this directory at the time of writing are for the `test-1` cluster. Thus the examples are for the `test-1` cluster but are still applicable for any cluster you wish to deploy to.

### File Changes

The `00-namespace.yaml` file should be left untouched, as no configuration is required. 

The main `kube-fluentd-es.yaml` requires a simple configuration, and it is essentially just the ElasticSearch endpoint URL.
In the `DaemonSet` section of the file, under the `env:` definition, you will see the following two lines of code:
```yaml
- name:  FLUENT_ELASTICSEARCH_HOST
    value: "search-cloud-platform-test-o2m2taivvjpovbcl63mlytnpua.eu-west-1.es.amazonaws.com"
```
The `value:` needs to be changed to the endpoint of the AWS Hosted ElasticSearch. To find your endpoint, navigate to the AWS ES dashboard in your browser and click on the name of your ElasticSearch domain.

Under the `Overview` tab, you will see your Endpoint URL. Copy this URL and paste it into the `value:` shown above. 

**IMPORTANT:** Make sure you remove the `https://` part of the URL in the `value:` otherwise it will not work.

As for the `kube-fluentd-es-config.yaml` file, in the vast majority of cases, this file can be left untouched and will work on an alternative cluster, as the variables it uses are pulled in from `kube-fluentd-es.yaml`. 

Being said, it may be worth familiarising yourself with the contents between the `<match>` tags, as this is there a lot of the variables that determine the behaviour of the flow of logs into ES is defined.

## Notes of considerations

* By default, Master Nodes have a Taint that prevents DaemonSets and other applications from deploying pods onto the node. In this case, we want to collect the logs of Master Nodes so the Toleration below was added to `kube-fluentd-es.yaml` to mitigate this:
```yaml
tolerations:
    - key: node-role.kubernetes.io/master
        effect: NoSchedule
```

* Currently the ElasticSearch domain accepts logs into it's endpoint based on IP Whitelisting. If you experience any connection issues, check the access policy for your ES Domain and ensure that the IP addresses for all of the availability zones for your cluster are properly defined in the policy.

